---
title: D06
description: Documentation Coverage
dimension: documentation
tags: [documentation,vision,roadmap,diagrams,models]
nav_order: 2.76

requirement: |
  The architecture documentation **SHOULD** be appropriate in scope and quality for the solution covering (but not exclusively) as defined in D06.

more_info: |
  Aim:
    Define the minimal yet sufficient set of artefacts providing a coherent,
    navigable representation of the solution—balancing thoroughness with
    maintainability.

  Coverage principles:
    - Intent before detail (vision & goals anchor subsequent design)
    - Decisions nearest to their impact (collocated ADR & affected diagram)
    - Non-functional concerns integrated, not an afterthought appendix
    - Traceability chain: Capability -> Requirement -> Design Element -> Decision
    - Automate generation where possible (diagrams-as-code, API specs)

  Prioritisation heuristic:
    1. Is the artefact required for governance approval or risk mitigation?
    2. Does it materially aid downstream engineering or operations?
    3. Is there an existing artefact fulfilling this need already?
    4. Can it be generated from source / model to avoid drift?

  Maintaining scope:
    - Use a catalogue table enumerating each artefact, purpose, owner, cadence
    - Explicitly list intentionally omitted artefacts with rationale (prevents rework)
    - Flag experimental / provisional sections separately

  Evidence examples:
    - Coverage matrix mapping artefacts to stakeholder concerns & principles
    - Generated site index linking to every required artefact with status badge
    - Automated completeness report (missing / stale items)

  Pitfalls:
    - Producing every possible artefact template irrespective of value
    - Duplicating similar diagrams at multiple abstraction levels with drift
    - Parking decisions only in meeting minutes (losing searchable context)

examples: 
    - title: Coverage Matrix Table
      content: |
        Rows: Artefact type; Columns: Purpose, Owner, Review Cadence, Status, Link.
    - title: Completeness Report
      content: |
        Script output enumerating missing or overdue artefacts with severity.
    - title: Traceability Chain Extract
      content: |
        YAML snippet linking capability IDs to design components and related ADR IDs.

technology:
    - title: Static Site Generator
      content: |
        Index & status badges for artefact catalogue.
    - title: Diagram-as-Code (PlantUML / Mermaid)
      content: |
        Enables regeneration & drift detection.
    - title: API Definition Tooling (OpenAPI / AsyncAPI)
      content: |
        Canonical interface specifications reduce duplication.
    - title: Scripted Completeness Auditor
      content: |
        Scans repository ensuring required artefacts present & dated.

further_reading:
    - title: ThoughtWorks Tech Radar (Documentation Practices)
      content: Guides trade-offs between completeness and sustainability.
      url: https://www.thoughtworks.com/radar
    - title: ISO/IEC/IEEE 42010
      content: Architecture description standard establishing viewpoint concepts.
      url: https://www.iso.org/standard/50508.html
    - title: Docs as Code
      content: Practice underpinning automated completeness & freshness.
      url: https://www.thoughtworks.com/radar/techniques/docs-as-code

assessment_guidance: |
  How to assess:
    1. Derive a catalogue (script or manual) of required artefacts vs present ones.
    2. Categorise each: Present & Current / Present but Stale / Missing (Justified / Unjustified).
    3. Evaluate traceability chain for one feature: Capability → Requirement / Objective → Design element → ADR → NFR → Operational metric.
    4. Identify intentional omissions with explicit rationale. Lack of rationale = gap.
    5. Review proportion of auto-generated vs manually maintained artefacts (seek automation opportunities for high-churn items).

  Evidence:
    - Coverage matrix (artefact, status, owner, cadence, gap_action).
    - Traceability example row.
    - Rationale list for omitted artefacts.
    - Automation inventory (what is generated & how).

  Common gaps:
    - “Parking lot” of TODO sections never resolved.
    - Orphan artefacts (no index reference / owner).
    - Excessive duplication (multiple overlapping diagrams or specs).

  Maturity signals:
    - Coverage >90% critical artefacts (with justified omissions documented).
    - Automated completeness report executed on CI or schedule.
    - Clear removal / archival workflow (no silent deletion).

  Quick wins:
    - Generate a machine-readable inventory (YAML) & validate on pipeline.
    - Add owner & review cadence fields if absent.
    - Combine / retire duplicate diagrams with little unique information.

assessment_examples:
  '0': |
      - No understanding of which artefacts “should” exist; purely organic accumulation.
      - Missing critical categories (no NFRs, risk, decision log, roadmap).
      - Duplicated / conflicting diagrams unlabelled.
    Inability to assess completeness or gaps.
      - Rudimentary list of a few artefact types; many absent with no rationale.
      - Manual attempts at inventory stale quickly.
      - Some fundamental documents (like ADRs) exist but poorly linked.
    Coverage incidental, not planned.
  '2': |
      - Inventory created capturing major artefact classes but lacking ownership / cadence metadata.
      - Gaps identified informally; no remediation tracking.
      - Redundant artefacts not yet rationalised.
    Foundation present; needs ownership & lifecycle.
      - Inventory covers most artefact types with owner roles for majority.
      - Gap list maintained; remediation items in backlog (mixed progress).
      - Duplicates flagged with consolidation notes; some resolved.
      - Coverage metric (present vs expected) produced occasionally.
    Structured but not fully enforced or automated.
  '4': |
      - Complete inventory (expected vs present) machine-generated; owners & review cadence populated.
      - Coverage KPI >90%; pending gaps have tracked actions & dates.
      - Automated check prevents removal of artefact without archival path.
      - Duplicate artefact reduction tracked (trend improving).
    Minor manual steps remain for niche artefact classes.
      - 100% expected artefact coverage or explicitly justified omission documented & approved.
      - Inventory + freshness + traceability dashboards integrated (single view).
      - Automated generation of “gap tickets” when a required artefact missing or overdue appears.
      - Duplicate detection & consolidation suggestions run continuously.
      - Continuous improvement metrics (coverage %, duplicate count, stale rate) all trending positively.
    Completeness process self-sustaining & adaptive.

documentation:
  - Architecture Vision 
  - Architecture Roadmap 
  - Layer Diagrams 
  - Capability Model 
  - Non functional requirements 
  - Conceptual Architecture 
  - Logical Architecture 
  - Physical (including network, infrastructure etc.) 
  - Solution Architecture Overview (SDO) 
  - Key Architecture Decisions (KADs) 
  - Data Models 
  - Data Flows 
  - API Specifications 
  - Volume and Performance Models 
  - Architecture Decision Records 
  - Assumption, Risks, Issues and Dependencies 
  - Cyber Assessment Framework compliance  








---
<ul>
{%- for document in page.documentation  -%}
<li>
{{ document  | markdownify}}
</li>
{% endfor %}
<ul>
