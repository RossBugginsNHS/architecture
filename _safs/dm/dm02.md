---
title: DM02
dimension: decisions
tags: [spend,finops]
nav_order: 2.22

description: Spend Control

requirement: |
  Spend control (GaTS) and associated Government Digital Services & Service Design related guidance **SHOULD** be followed whilst developing the solution and be evidenced for service design & spend control reviews.

more_info: |
  Purpose:
    Ensure financial governance (GaTS / spend control) is integral to design
    evolution—not a late compliance gate—so architectural choices reflect cost
    transparency and value realisation.

  Core alignment areas:
    - Strategic fit & problem framing (business case coherence)
    - Options considered (including reuse / buy vs build)
    - Whole-life cost model (run + change + exit)
    - Benefit tracking approach & measurable outcomes
    - Risk & dependency profile (including market / vendor exposure)

  Evidence lifecycle:
    1. Early concept note ties capability gap to strategic objective
    2. Option appraisal (qual & quant) with TCO comparisons
    3. Preferred option rationale (trade-offs & rejected options)
    4. Incremental funding checkpoints linked to milestone value
    5. Post-implementation value realisation review

  Cost hygiene practices:
    - Tag infrastructure / workloads for cost allocation early
    - Model scaling cost vs projected usage (avoid surprise inflection)
    - Track cost per key transaction / user segment
    - Include decommissioning / migration expenses in TCO

  Pitfalls:
    - Treating spend control forms as paperwork after architecture decided
    - Optimising for procurement cost ignoring run/operations cost curve
    - Under-accounting for data egress / inter-service latency cost implications

examples: 
    - title: Option Appraisal Table
      content: |
        Columns: Option, CapEx, OpEx (3yr), Vendor Lock Risk, Time-to-Value,
        Strategic Alignment Score, Preferred (Y/N), Rationale.
    - title: Cost per Transaction Metric
      content: |
        Dashboard slice showing trend of average cost per processed event vs
        forecast envelope.
    - title: Incremental Funding Gate Checklist
      content: |
        Realisation evidence pack summarising achieved vs planned outcomes.

technology:
    - title: FinOps Cost Explorer / Cloud Billing API
      content: |
        Provides tagged cost data for allocation & optimisation.
    - title: Modelling Spreadsheet / Tool
      content: |
        Projects TCO & sensitivity (scale, pricing changes, usage variance).
    - title: Dashboard (Grafana / Looker)
      content: |
        Visualises cost KPIs & budget adherence.
    - title: Option Appraisal Template (Markdown)
      content: |
        Standardised structure for decision evidence.

further_reading:
    - title: FinOps Foundation
      content: Cloud financial management best practices.
      url: https://www.finops.org/
    - title: GDS Spend Control Guidance
      content: Government digital spend governance principles.
      url: https://www.gov.uk/guidance/the-technology-code-of-practice
    - title: TCO Analysis (AWS)
      content: Framework for whole-life cost modelling.
      url: https://aws.amazon.com/tco/

assessment_guidance: |
  Assessment focus:
    Validate that architectural decisions internalise cost transparency, option appraisal and benefit realisation—not just satisfy a paperwork gateway.

  Steps:
    1. Review the latest option appraisal: confirm at least one reuse/do‑nothing baseline and explicit rejection rationale.
    2. Inspect TCO model inputs (run, change, exit, compliance overhead); challenge hidden assumptions (e.g. unpriced data egress / support tiers).
    3. Trace two architectural components to tagged cost dashboards: verify cost allocation granularity (service / environment / team).
    4. Examine benefit tracking artefact: ensure KPIs are leading and attributable (not only lagging financials).
    5. Check funding gates: sample one recently passed gate for evidence pack completeness (decision log, risk updates, cost variance analysis).

  Evidence:
    - Option appraisal comparison table
    - Extract of cost tags & monthly allocation report
    - TCO spreadsheet (sanitised) highlighting sensitivity analysis
    - Benefit realisation dashboard screenshot

  Red flags:
    - Single-option business cases
    - CapEx focus with opaque ongoing OpEx scaling assumptions
    - Large variance between forecast and actual with no corrective plan
    - No linkage between cost anomalies and architectural refactors

  Maturity signals:
    - Automated nightly ingestion of cost + usage metrics feeding forecast variance
    - Regular (e.g. quarterly) recalibration of TCO assumptions
    - Architecture runway items explicitly tied to cost optimisation hypotheses

  Quick improvements:
    - Add “assumptions & triggers” section to cost model
    - Introduce cost per key transaction KPI and publish trend
    - Embed FinOps review in decision template before approval

assessment_examples:
  '0':
    - example: No option appraisal; single preferred solution justified only qualitatively.
    - example: Costs tracked loosely (one-off estimate) with no run / exit model.
    - example: No linkage between architectural choices and spend control guidance.
  '1':
    - example: Basic business case with CapEx focus; OpEx & exit costs missing.
    - example: Options section lists alternatives but lacks comparative metrics.
    - example: Cost tagging inconsistent; cannot attribute spend to major components.
  '2':
    - example: Option appraisal includes TCO but assumptions undocumented; reuse baseline weak.
    - example: Initial tagging implemented; some resources untagged or mis-tagged.
    - example: Benefit KPIs high-level and lagging (e.g. annual savings only).
  '3':
    - example: Multi-option appraisal with qualitative + quantitative comparison (cost, risk, value) and clear rejection rationale.
    - example: Cost allocation tags cover majority workloads enabling per-component visibility.
    - example: Incremental funding gates evidenced with outcome variance assessment.
  '4':
    - example: Whole-life cost model (run, change, support, exit) versioned & recalibrated quarterly.
    - example: Cost per key transaction / user segment tracked with alert thresholds.
    - example: Forecast vs actual variance reported; corrective design actions documented.
  '5':
    - example: Automated ingestion of cost & usage metrics feeds live forecast variance dashboards.
    - example: Architectural proposals include sensitivity & scenario analysis; reuse / do-nothing consistently evaluated.
    - example: Benefit realisation tracking links architecture milestones to measurable outcome deltas.
    - example: Funding decisions traceable to ADRs and updated when cost signals breach thresholds.



---
