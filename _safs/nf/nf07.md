---
title: NF07
description: Accessibility & UX
dimension: non functional
tags: [accessibility,legislation,inclusion,wcag,usability,assistive,compliance,design,testing,inclusive-design,user-research]
nav_order: 2.57
deprecated: true

requirement: |
  The architecture **MUST** support the ability to maximise the UX and supports accessibility needs and legislation. 

more_info: |
  Intent:
    Ensure architecture supports accessible, inclusive user experience meeting
    legislative and ethical standards while maintaining product velocity.

  Accessibility integration:
    - Shift-left design reviews with assistive tech personas
    - Component library with baked-in accessibility (semantic markup, ARIA)
    - Continuous automated a11y scans + manual audits for complex flows
    - Performance budgets (fast response benefits accessibility)
    - Internationalisation & localisation readiness

  Metrics / signals:
    - % components with accessibility test coverage
    - Defect density of a11y issues per release
    - Keyboard-only navigation journey success rate
    - Colour contrast compliance %

  Pitfalls:
    - Treating accessibility as post-hoc compliance check
    - Reliance solely on automated scanners (they miss contextual issues)
    - Custom widgets reinventing native control semantics

examples: 
    - title: Accessible Component Example
      content: |
        Modal with focus trap, escape handling, labelled title region.
    - title: A11y Audit Report Extract
      content: |
        Issues grouped by severity with remediation owners.
    - title: Keyboard Navigation Test Script
      content: |
        Stepwise validation of primary user journey without mouse.

technology:
    - title: Automated Accessibility Scanner (axe / pa11y)
      content: |
        Baseline detection of WCAG failures.
    - title: Design System / Component Library
      content: |
        Reusable accessible components reduce rework.
    - title: Screen Reader (NVDA / VoiceOver)
      content: |
        Manual validation of semantic ordering & labelling.

further_reading:
    - title: WCAG 2.2 Guidelines
      content: Accessibility success criteria.
      url: https://www.w3.org/TR/WCAG22/
    - title: GOV.UK Accessibility Guidance
      content: Practical implementation guidance.
      url: https://www.gov.uk/service-manual/helping-people-to-use-your-service

assessment_guidance: |
  Assessment focus:
    Validate accessibility is engineered into architecture & delivery processes, not retrofitted.

  Steps:
    1. Inspect component library: ensure accessibility tests (unit/integration) exist for interactive components.
    2. Review automated scan pipeline logs & manual audit schedule; confirm recent executive summary of findings.
    3. Sample 2 complex user journeys with keyboard-only & screen readerâ€”verify no blocking issues.
    4. Examine metrics (contrast issues, duplicate IDs, focus trap escapes) trend across releases.
    5. Check ADRs / design docs for inclusive design considerations & performance trade-offs.

  Evidence:
    - Component test snapshot
    - Latest audit report excerpt
    - Journey walkthrough notes
    - Accessibility metrics dashboard

  Red flags:
    - Only automated scanner evidence (no manual audits)
    - Recurrent regressions in same components
    - Accessibility bugs triaged as low priority consistently

  Maturity signals:
    - Accessibility debt backlog shrinking with SLA adherence
    - Inclusive design review a gate in design process
    - Performance budgets supporting a11y (fast load aiding users)

  Quick improvements:
    - Add accessibility acceptance criteria to definition of done
    - Automate a11y snapshot diffs for regressions
    - Publish public accessibility statement with update cadence

assessment_examples:
  "0":
    - example: No accessibility consideration; components fail basic keyboard navigation and contrast checks.
    - example: Reliance solely on manual ad-hoc testing when issues are reported by users.
  "1":
    - example: Occasional automated scan run locally; numerous WCAG issues outstanding; no ownership model.
    - example: Component library missing semantic markup patterns.
  "2":
    - example: Automated pipeline scans for core pages; backlog of issues triaged but resolution sporadic.
    - example: Some components include ARIA labels; screen reader testing irregular.
  "3":
    - example: Defined accessibility test suite (axe/pa11y + keyboard scripts) executed per build; defect SLA established.
    - example: Inclusive design considerations appear in ADRs and design reviews.
  "4":
    - example: Metrics (contrast compliance, keyboard journey success) trending positively; regression gates blocking merges.
    - example: Complex interactive components (modals, menus) fully accessible with focus management and announcements.
  "5":
    - example: Accessibility debt burn-down steady; automated diffing of snapshots prevents visual/semantic regressions.
    - example: User research includes assistive tech participants regularly influencing component evolution.








---
